{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOH7bDOZirAXl3kPEQyXB7Z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jaksta1/Monte-Carlo-method-for-option-prices/blob/main/skrypt%20mgr.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YemDJFrqA5Jy"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from scipy.stats import norm\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from qmcpy import Sobol\n",
        "\n",
        "# ---------------------------\n",
        "# QMC -> normals (QMCPy Sobol, randomize=True gives full Owen scramble)\n",
        "# ---------------------------\n",
        "def qmc_normals_qmcpy(n_paths, total_dim, seed=None):\n",
        "    \"\"\"Zwraca tablicę (n_paths, total_dim) z punktami Sobola przekształconymi do N(0,1).\"\"\"\n",
        "    sob = Sobol(dimension=total_dim, randomize=True, seed=seed)\n",
        "    u = sob.gen_samples(n_paths)  # shape (n_paths, total_dim)\n",
        "    eps = 1e-16\n",
        "    u = np.clip(u, eps, 1 - eps)\n",
        "    return norm.ppf(u)\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# Rozszerzony MARS (LDA + GCV)\n",
        "# ---------------------------\n",
        "class ExtendedMARS:\n",
        "    def __init__(self, max_terms=20, min_leaf=10, penalty=3.0):\n",
        "        self.max_terms = int(max_terms)\n",
        "        self.min_leaf = int(min_leaf)\n",
        "        self.penalty = float(penalty)\n",
        "        self.basis = []   # list of (a, knot, sign)\n",
        "        self.coefs = None\n",
        "        self.intercept_ = 0.0\n",
        "\n",
        "    def _project(self, X, a):\n",
        "        return X.dot(a)\n",
        "\n",
        "    def _gcv(self, y, y_pred, n_params):\n",
        "        n = len(y)\n",
        "        rss = np.sum((y - y_pred) ** 2)\n",
        "        C = n_params + self.penalty\n",
        "        if n <= C:\n",
        "            return rss  # fallback\n",
        "        denom = (1.0 - C / n) ** 2\n",
        "        return rss / denom\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        X = np.asarray(X)\n",
        "        y = np.asarray(y).ravel()\n",
        "        n, d = X.shape\n",
        "        design = np.ones((n, 1))  # intercept\n",
        "        self.basis = []\n",
        "\n",
        "        for step in range(self.max_terms):\n",
        "            coef_curr, *_ = np.linalg.lstsq(design, y, rcond=None)\n",
        "            y_pred_curr = design.dot(coef_curr)\n",
        "            residual = y - y_pred_curr\n",
        "\n",
        "            # candidate directions: LDA on sign of residuals (two classes)\n",
        "            try:\n",
        "                labels = (residual > np.median(residual)).astype(int)\n",
        "                lda = LinearDiscriminantAnalysis(n_components=1)\n",
        "                lda.fit(X, labels)\n",
        "                a_candidate = lda.coef_[0]\n",
        "                if np.linalg.norm(a_candidate) > 0:\n",
        "                    a_candidate = a_candidate / (np.linalg.norm(a_candidate) + 1e-12)\n",
        "                    candidate_dirs = [a_candidate]\n",
        "                else:\n",
        "                    candidate_dirs = [np.eye(d)[j] for j in range(d)]\n",
        "            except Exception:\n",
        "                candidate_dirs = [np.eye(d)[j] for j in range(d)]\n",
        "\n",
        "            best_gcv = np.inf\n",
        "            best_tuple = None  # (a, knot, sign, col)\n",
        "\n",
        "            for a in candidate_dirs:\n",
        "                proj = self._project(X, a)\n",
        "                # candidate knots: percentyle w zakresie [10,90]\n",
        "                nknots = max(2, min(12, n // max(1, self.min_leaf)))\n",
        "                percentiles = np.linspace(10, 90, nknots)\n",
        "                knots = np.unique(np.percentile(proj, percentiles))\n",
        "                for knot in knots:\n",
        "                    for sign in (+1, -1):\n",
        "                        if sign == 1:\n",
        "                            col = np.maximum(proj - knot, 0.0)[:, None]\n",
        "                        else:\n",
        "                            col = np.maximum(knot - proj, 0.0)[:, None]\n",
        "                        if np.allclose(col, 0.0):\n",
        "                            continue\n",
        "                        D = np.hstack([design, col])\n",
        "                        coef_try, *_ = np.linalg.lstsq(D, y, rcond=None)\n",
        "                        y_try = D.dot(coef_try)\n",
        "                        gcv = self._gcv(y, y_try, D.shape[1])\n",
        "                        if gcv < best_gcv - 1e-12:\n",
        "                            best_gcv = gcv\n",
        "                            best_tuple = (a.copy(), float(knot), int(sign), col)\n",
        "\n",
        "            if best_tuple is None:\n",
        "                break\n",
        "            # accept basis\n",
        "            a_best, knot_best, sign_best, col_best = best_tuple\n",
        "            self.basis.append((a_best, knot_best, sign_best))\n",
        "            design = np.hstack([design, col_best])\n",
        "\n",
        "        # final fit\n",
        "        coef_final, *_ = np.linalg.lstsq(design, y, rcond=None)\n",
        "        self.intercept_ = float(coef_final[0])\n",
        "        if design.shape[1] > 1:\n",
        "            self.coefs = coef_final[1:].astype(float)\n",
        "        else:\n",
        "            self.coefs = np.array([], dtype=float)\n",
        "\n",
        "        # backward pruning based on GCV (try removing each basis if improves GCV)\n",
        "        improved = True\n",
        "        while improved and len(self.basis) > 0:\n",
        "            improved = False\n",
        "            # build design once per iteration\n",
        "            D_full = np.ones((n, 1))\n",
        "            for (a, knot, sign) in self.basis:\n",
        "                proj = self._project(X, a)\n",
        "                col = (np.maximum(proj - knot, 0.0) if sign == 1 else np.maximum(knot - proj, 0.0))[:, None]\n",
        "                D_full = np.hstack([D_full, col])\n",
        "            coef_full, *_ = np.linalg.lstsq(D_full, y, rcond=None)\n",
        "            gcv_full = self._gcv(y, D_full.dot(coef_full), D_full.shape[1])\n",
        "            # test removals\n",
        "            for idx in range(len(self.basis)):\n",
        "                basis_try = self.basis[:idx] + self.basis[idx + 1:]\n",
        "                D_try = np.ones((n, 1))\n",
        "                for (a, knot, sign) in basis_try:\n",
        "                    proj = self._project(X, a)\n",
        "                    col = (np.maximum(proj - knot, 0.0) if sign == 1 else np.maximum(knot - proj, 0.0))[:, None]\n",
        "                    D_try = np.hstack([D_try, col])\n",
        "                coef_try, *_ = np.linalg.lstsq(D_try, y, rcond=None)\n",
        "                gcv_try = self._gcv(y, D_try.dot(coef_try), D_try.shape[1])\n",
        "                if gcv_try < gcv_full - 1e-12:\n",
        "                    # accept pruning\n",
        "                    self.basis = basis_try\n",
        "                    self.intercept_ = float(coef_try[0])\n",
        "                    self.coefs = (coef_try[1:].astype(float) if D_try.shape[1] > 1 else np.array([], dtype=float))\n",
        "                    improved = True\n",
        "                    break\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        X = np.asarray(X)\n",
        "        n = X.shape[0]\n",
        "        y_pred = np.full(n, self.intercept_, dtype=float)\n",
        "        for idx, (a, knot, sign) in enumerate(self.basis):\n",
        "            proj = self._project(X, a)\n",
        "            term = (np.maximum(proj - knot, 0.0) if sign == 1 else np.maximum(knot - proj, 0.0))\n",
        "            coef = self.coefs[idx] if idx < len(self.coefs) else 0.0\n",
        "            y_pred += coef * term\n",
        "        return y_pred\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# LSM + faza II (L_hat, U_hat) używając ExtendedMARS\n",
        "# ---------------------------\n",
        "class LSM_MARS_QMC:\n",
        "    def __init__(self, simulator_func, payoff_func, times, r, dim, mars_params=None, rng_seed=None):\n",
        "        \"\"\"\n",
        "        simulator_func: callable(normals) -> paths shape (n_paths, n_steps, dim)\n",
        "          where normals shape is (n_paths, n_steps, dim) standard normals.\n",
        "        payoff_func: callable(t_index, x_vector) -> scalar payoff\n",
        "        times: array of time grid (length n_steps)\n",
        "        r: interest rate (annual)\n",
        "        dim: dimension of underlying (liczba aktywów)\n",
        "        mars_params: dict for ExtendedMARS\n",
        "        rng_seed: optional seed for reproducibility\n",
        "        \"\"\"\n",
        "        self.simulator = simulator_func\n",
        "        self.payoff = payoff_func\n",
        "        self.times = np.asarray(times)\n",
        "        self.dt = np.diff(self.times)\n",
        "        self.r = float(r)\n",
        "        self.dim = int(dim)\n",
        "        self.mars_params = mars_params or {}\n",
        "        self.rng = np.random.default_rng(rng_seed)\n",
        "        # model parameters (mu, sigma) needed for simulator_one_step in phase II\n",
        "        self.mu = None\n",
        "        self.sigma = None\n",
        "\n",
        "    def set_model_params(self, mu, sigma):\n",
        "        self.mu = np.asarray(mu, dtype=float)\n",
        "        self.sigma = np.asarray(sigma, dtype=float)\n",
        "\n",
        "    def simulator_one_step(self, x_prev, z_stdnormal, step_index):\n",
        "        \"\"\"\n",
        "        Jednokrokowa symulacja GBM (wektorowa). Zakładamy model GBM dla każdego aktywa niezależnie.\n",
        "        x_prev: (dim,)\n",
        "        z_stdnormal: (dim,) standard normals\n",
        "        step_index: indeks kroku docelowego (j), symulujemy z t_{j-1} -> t_j\n",
        "        \"\"\"\n",
        "        if self.mu is None or self.sigma is None:\n",
        "            raise RuntimeError(\"set_model_params(mu, sigma) must be called before simulator_one_step.\")\n",
        "        # dt for step from t_{j-1} to t_j\n",
        "        if step_index <= 0:\n",
        "            raise ValueError(\"step_index must be >= 1 for one-step simulation\")\n",
        "        dt = self.times[step_index] - self.times[step_index - 1]\n",
        "        drift = (self.mu - 0.5 * (self.sigma ** 2)) * dt\n",
        "        diffusion = self.sigma * np.sqrt(dt) * z_stdnormal\n",
        "        return x_prev * np.exp(drift + diffusion)\n",
        "\n",
        "    def _generate_normals(self, n_paths, seed_offset=0):\n",
        "        n_steps = len(self.times)\n",
        "        total_dim = n_steps * self.dim\n",
        "        # seed_offset passed into seed for QMCPy for reproducibility; QMCPy expects integer seed or None\n",
        "        seed = None if seed_offset is None else int(seed_offset)\n",
        "        u = qmc_normals_qmcpy(n_paths, total_dim, seed=seed)\n",
        "        normals = u.reshape(n_paths, n_steps, self.dim)\n",
        "        return normals\n",
        "\n",
        "    def price(self, N1=1024, N2=512, max_terms=12, inner_MC=64):\n",
        "        \"\"\"\n",
        "        Wykonaj fazę I (N1) oraz fazę II (N2). Zwróć L_hat i U_hat.\n",
        "        inner_MC: liczba symulacji wewnętrznych do estymacji E[h_t | X_{t-1}]\n",
        "        \"\"\"\n",
        "        n_steps = len(self.times)\n",
        "        # Phase I: fit models on N1 QMC paths\n",
        "        normals1 = self._generate_normals(N1, seed_offset=11)\n",
        "        X1 = self.simulator(normals1)  # (N1, n_steps, dim)\n",
        "        # compute immediate payoffs matrix\n",
        "        B = np.zeros((N1, n_steps))\n",
        "        for i in range(N1):\n",
        "            for j in range(n_steps):\n",
        "                B[i, j] = float(self.payoff(j, X1[i, j, :]))\n",
        "\n",
        "        models = [None] * n_steps\n",
        "        # terminal\n",
        "        models[-1] = None  # terminal value is payoff\n",
        "\n",
        "        # backward induction LSM + MARS (fit B_j)\n",
        "        for j in range(n_steps - 2, -1, -1):\n",
        "            disc = np.exp(-self.r * self.dt[j])\n",
        "            # target: value = max(immediate payoff, discounted next)\n",
        "            Y = np.maximum(B[:, j], disc * B[:, j + 1])\n",
        "            X_train = X1[:, j, :]\n",
        "            model = ExtendedMARS(max_terms=max_terms, **self.mars_params)\n",
        "            model.fit(X_train, Y)\n",
        "            models[j] = model\n",
        "            cont = model.predict(X_train)\n",
        "            exercise = B[:, j] > cont\n",
        "            B[:, j] = np.where(exercise, B[:, j], disc * B[:, j + 1])\n",
        "\n",
        "        # Phase II: estimate L_hat and U_hat on independent N2 QMC paths\n",
        "        normals2 = self._generate_normals(N2, seed_offset=999)\n",
        "        X2 = self.simulator(normals2)\n",
        "        L_vals = np.zeros(N2)\n",
        "        U_vals = np.zeros(N2)\n",
        "\n",
        "        for i in range(N2):\n",
        "            pi = 0.0\n",
        "            stopped = False\n",
        "            for j in range(n_steps):\n",
        "                t = self.times[j]\n",
        "                g = float(self.payoff(j, X2[i, j, :]))\n",
        "                h = float(models[j].predict(X2[i, j, :].reshape(1, -1))[0]) if models[j] else g\n",
        "\n",
        "                if j > 0:\n",
        "                    x_prev = X2[i, j - 1, :]\n",
        "                    zs = self.rng.standard_normal(size=(inner_MC, self.dim))\n",
        "                    x_next_samples = np.array([self.simulator_one_step(x_prev, zs[k], j) for k in range(inner_MC)])\n",
        "                    h_vals = models[j].predict(x_next_samples) if models[j] else np.array([float(self.payoff(j, xn)) for xn in x_next_samples])\n",
        "                    h_cond = float(np.mean(h_vals))\n",
        "                else:\n",
        "                    h_cond = h  # zamiast 0\n",
        "\n",
        "                pi += h - h_cond  # bez dodatkowego dyskontowania\n",
        "\n",
        "                # Lower bound\n",
        "                if not stopped and g > h:\n",
        "                    L_vals[i] = np.exp(-self.r * t) * g\n",
        "                    stopped = True\n",
        "\n",
        "                # Upper bound\n",
        "                cand = np.exp(-self.r * t) * (g - pi)\n",
        "                if cand > U_vals[i]:\n",
        "                    U_vals[i] = cand\n",
        "\n",
        "            if not stopped:\n",
        "                L_vals[i] = np.exp(-self.r * self.times[-1]) * float(self.payoff(n_steps - 1, X2[i, -1, :]))\n",
        "\n",
        "        L_hat = float(np.mean(L_vals))\n",
        "        U_hat = float(np.mean(U_vals))\n",
        "        return {\"L_hat\": L_hat, \"U_hat\": U_hat, \"models\": models}\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# GBM simulator (użyty jako przykład)\n",
        "# ---------------------------\n",
        "def gbm_simulator_factory(S0, mu, sigma, times):\n",
        "    \"\"\"\n",
        "    simulator(normals) -> paths with shape (n_paths, n_steps, dim)\n",
        "    normals expected shape: (n_paths, n_steps, dim) standard normals\n",
        "    \"\"\"\n",
        "    S0 = np.array(S0, dtype=float)\n",
        "    mu = np.array(mu, dtype=float)\n",
        "    sigma = np.array(sigma, dtype=float)\n",
        "    times = np.array(times, dtype=float)\n",
        "    dt = np.diff(times)\n",
        "    n_steps = len(times)\n",
        "    dim = len(S0)\n",
        "\n",
        "    def simulator(normals):\n",
        "        normals = np.asarray(normals)\n",
        "        n_paths = normals.shape[0]\n",
        "        paths = np.empty((n_paths, n_steps, dim), dtype=float)\n",
        "        for i in range(n_paths):\n",
        "            S = S0.copy()\n",
        "            paths[i, 0, :] = S\n",
        "            for j in range(1, n_steps):\n",
        "                z = normals[i, j, :]\n",
        "                S = S * np.exp((mu - 0.5 * sigma ** 2) * dt[j - 1] + sigma * np.sqrt(dt[j - 1]) * z)\n",
        "                paths[i, j, :] = S\n",
        "        return paths\n",
        "\n",
        "    return simulator\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# Przykładowe uruchomienie\n",
        "# ---------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    # parametry modelu\n",
        "    S0 = [100.0]                # single asset\n",
        "    mu = np.array([0.03])\n",
        "    sigma = np.array([0.2])\n",
        "    r = 0.03\n",
        "    T = 1.0\n",
        "    Nsteps = 100\n",
        "    times = np.linspace(0.0, T, Nsteps + 1)\n",
        "\n",
        "    # payoff: american put on single asset\n",
        "    K = 100.0\n",
        "    payoff = lambda j, x: max(K - float(np.sum(x)), 0.0)\n",
        "\n",
        "    # stwórz symulator i pricer\n",
        "    sim = gbm_simulator_factory(S0, mu, sigma, times)\n",
        "    pricer = LSM_MARS_QMC(simulator_func=sim, payoff_func=payoff, times=times, r=r, dim=1,\n",
        "                          mars_params={\"min_leaf\": 5, \"penalty\": 3.0}, rng_seed=12345)\n",
        "    # ustaw parametry modelu potrzebne do simulator_one_step\n",
        "    pricer.set_model_params(mu=mu, sigma=sigma)\n",
        "\n",
        "    # uruchom (dobierz N1,N2,inner_MC w zależności od mocy obliczeniowej)\n",
        "    for N1 in (1024, 2048, 4096, 8192):\n",
        "        for N2 in (1024, 2048, 4096, 8192):\n",
        "            res = pricer.price(N1=N1, N2=N2, max_terms=8, inner_MC=32)\n",
        "            print(f\"Przedział wyceny: L̂ = {res['L_hat']:.6f}, Û = {res['U_hat']:.6f}, N1 = {N1}, N2 = {N2}\")\n"
      ]
    }
  ]
}