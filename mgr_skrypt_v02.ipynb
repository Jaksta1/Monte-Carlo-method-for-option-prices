{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNoAUZg/D8hI5iKHU51DPdA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jaksta1/Monte-Carlo-method-for-option-prices/blob/main/mgr_skrypt_v02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z3vzVcuPmAw2"
      },
      "outputs": [],
      "source": [
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "Finalny skrypt: wycena opcji amerykańskiej (Ehrlichman-Henderson style)\n",
        "- QMC (qmcpy Sobol/Halton)\n",
        "- Extended MARS z LDA i GCV\n",
        "- LSM + martingale control variate\n",
        "- Poprawne dyskontowanie (używa dt)\n",
        "\"\"\"\n",
        "import numpy as np\n",
        "from scipy.stats import norm\n",
        "from qmcpy import Sobol, Halton\n",
        "from typing import Callable, Tuple, Optional\n",
        "from typing import Callable, Tuple, Optional, List, Dict\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# Pomocnicze funkcje\n",
        "# ---------------------------\n",
        "\n",
        "def _next_pow2(x: int) -> int:\n",
        "    if x <= 0:\n",
        "        return 1\n",
        "    return 1 << int(np.ceil(np.log2(x)))\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# Symulacja ścieżek QMC (z prefetch i dopełnieniem)\n",
        "# ---------------------------\n",
        "\n",
        "def simulate_paths(\n",
        "    S0: np.ndarray,\n",
        "    r: float,\n",
        "    sigma: np.ndarray,\n",
        "    rho: np.ndarray,\n",
        "    n_steps: int,\n",
        "    T: float,\n",
        "    N: int,\n",
        "    qmc_sampler,\n",
        "    seed: Optional[int] = None\n",
        ") -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Generuje N ścieżek d-wymiarowego Black-Scholesa z korelacjami.\n",
        "    \"\"\"\n",
        "    d = len(S0)\n",
        "    dt = T / n_steps\n",
        "    paths = np.zeros((N, n_steps + 1, d))\n",
        "    paths[:, 0, :] = S0\n",
        "\n",
        "    # Cholesky korelacji\n",
        "    L = np.linalg.cholesky(rho)\n",
        "\n",
        "    # Generuj próbki dla wszystkich kroków czasowych naraz\n",
        "    total_dim = n_steps * d\n",
        "    # Generujemy N próbek o wymiarze (n_steps * d)\n",
        "    u = qmc_sampler.gen_samples(n_min=0, n_max=N)  # (N, total_dim)\n",
        "    if u.shape[1] != total_dim:\n",
        "        # Jeśli wymiar próbek jest nieprawidłowy, generujemy jeszcze raz z właściwym wymiarem\n",
        "        qmc_sampler = Sobol(dimension=total_dim, randomize='Owen', seed=seed)\n",
        "        u = qmc_sampler.gen_samples(n_min=0, n_max=N)\n",
        "\n",
        "    # Zapobiegaj skrajnym wartościom\n",
        "    eps = 1e-12\n",
        "    u = np.clip(u, eps, 1 - eps)\n",
        "\n",
        "    # Przekształć na normalne\n",
        "    z = norm.ppf(u)\n",
        "\n",
        "    # Przekształć na właściwy kształt (N, n_steps, d)\n",
        "    z = z.reshape(N, n_steps, d)\n",
        "\n",
        "    # Aplikuj korelację\n",
        "    for t in range(n_steps):\n",
        "        z[:, t, :] = z[:, t, :] @ L.T\n",
        "\n",
        "    # Symuluj ścieżki\n",
        "    drift = (r - 0.5 * sigma**2) * dt\n",
        "    diffusion = sigma * np.sqrt(dt)\n",
        "\n",
        "    for t in range(n_steps):\n",
        "        paths[:, t+1] = paths[:, t] * np.exp(\n",
        "            drift + diffusion * z[:, t]\n",
        "        )\n",
        "\n",
        "    return paths\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# Extended MARS z LDA + GCV\n",
        "# ---------------------------\n",
        "\n",
        "class ExtendedMARS:\n",
        "    \"\"\"\n",
        "    Extended MARS (Multivariate Adaptive Regression Splines) z LDA i GCV\n",
        "    \"\"\"\n",
        "    def __init__(self, max_terms: int = 20, min_obs_per_knot: int = 20, penalty: float = 3.0):\n",
        "        self.max_terms = max_terms\n",
        "        self.min_obs_per_knot = min_obs_per_knot\n",
        "        self.base_penalty = penalty\n",
        "\n",
        "        # Parametry modelu\n",
        "        self.a0: float = 0.0\n",
        "        self.alphas: List[float] = []\n",
        "        self.directions: List[np.ndarray] = []\n",
        "        self.knots: List[float] = []\n",
        "        self.signs: List[int] = []\n",
        "\n",
        "        # Diagnostyka\n",
        "        self.gcv_scores: List[float] = []\n",
        "        self.r2_scores: List[float] = []\n",
        "\n",
        "    def _get_lda_directions(self, X: np.ndarray, y: np.ndarray, n_splits: int = 5) -> List[np.ndarray]:\n",
        "        \"\"\"Generuje kierunki LDA używając wielu punktów podziału danych\"\"\"\n",
        "        directions = []\n",
        "        splits = np.linspace(0, 100, n_splits+2)[1:-1]\n",
        "\n",
        "        for percentile in splits:\n",
        "            try:\n",
        "                threshold = np.percentile(y, percentile)\n",
        "                labels = (y > threshold).astype(int)\n",
        "\n",
        "                if len(np.unique(labels)) > 1:\n",
        "                    lda = LinearDiscriminantAnalysis(n_components=min(X.shape[1], 1))\n",
        "                    lda.fit(X, labels)\n",
        "\n",
        "                    v = lda.scalings_[:, 0].copy()\n",
        "                    normv = np.linalg.norm(v)\n",
        "                    if normv > 0:\n",
        "                        v /= normv\n",
        "                        if not any(np.allclose(v, d) for d in directions):\n",
        "                            directions.append(v)\n",
        "            except Exception as e:\n",
        "                warnings.warn(f\"LDA nie powiodło się dla percentyla {percentile}: {str(e)}\")\n",
        "                continue\n",
        "\n",
        "        return directions\n",
        "\n",
        "    def _gcv(self, y: np.ndarray, yhat: np.ndarray, num_params: int,\n",
        "             adaptive_penalty: bool = True) -> float:\n",
        "        \"\"\"Oblicza score GCV z adaptacyjną karą\"\"\"\n",
        "        n = len(y)\n",
        "        rss = np.sum((y - yhat)**2)\n",
        "\n",
        "        if adaptive_penalty:\n",
        "            penalty = self.base_penalty + 0.1 * np.log(num_params + 1)\n",
        "        else:\n",
        "            penalty = self.base_penalty\n",
        "\n",
        "        p = max(1, num_params) + 1\n",
        "        denom = (1 - penalty * p / n)**2\n",
        "\n",
        "        if denom <= 0:\n",
        "            return np.inf\n",
        "\n",
        "        gcv_score = (rss / n) / denom\n",
        "        complexity_penalty = np.log(p) * rss / n\n",
        "\n",
        "        return gcv_score + complexity_penalty\n",
        "\n",
        "    def _generate_knots(self, proj: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"Generuje kandydackie węzły\"\"\"\n",
        "        percentiles = [5, 10, 20, 30, 40, 50, 60, 70, 80, 90, 95]\n",
        "        knots = np.percentile(proj, percentiles)\n",
        "\n",
        "        valid_knots = []\n",
        "        for k in knots:\n",
        "            if (proj <= k).sum() >= self.min_obs_per_knot and \\\n",
        "               (proj > k).sum() >= self.min_obs_per_knot:\n",
        "                valid_knots.append(k)\n",
        "\n",
        "        return np.array(valid_knots)\n",
        "\n",
        "    def _check_linear_independence(self, new_term: np.ndarray,\n",
        "                                 current_terms: List[np.ndarray]) -> bool:\n",
        "        \"\"\"Sprawdza liniową niezależność\"\"\"\n",
        "        if not current_terms:\n",
        "            return True\n",
        "\n",
        "        for term in current_terms:\n",
        "            corr = np.corrcoef(new_term, term)[0, 1]\n",
        "            if abs(corr) > 0.99:\n",
        "                return False\n",
        "        return True\n",
        "\n",
        "    def fit(self, X: np.ndarray, y: np.ndarray) -> 'ExtendedMARS':\n",
        "        \"\"\"Dopasowuje model MARS do danych\"\"\"\n",
        "        n, d = X.shape\n",
        "        X = np.asarray(X)\n",
        "        y = np.asarray(y)\n",
        "\n",
        "        self.a0 = float(np.mean(y))\n",
        "        residual = y - self.a0\n",
        "\n",
        "        directions = [np.eye(d)[i] for i in range(d)]\n",
        "        lda_directions = self._get_lda_directions(X, y)\n",
        "        directions.extend(lda_directions)\n",
        "\n",
        "        directions = [d for i, d in enumerate(directions)\n",
        "                     if not any(np.allclose(d, p) for p in directions[:i])]\n",
        "\n",
        "        terms = [np.ones(n)]\n",
        "        preds = [np.full_like(y, self.a0)]\n",
        "        self.gcv_scores = [self._gcv(y, preds[0], 1)]\n",
        "\n",
        "        for term_idx in range(self.max_terms):\n",
        "            best_gcv = np.inf\n",
        "            best_config = None\n",
        "\n",
        "            for a in directions:\n",
        "                proj = X @ a\n",
        "                knots = self._generate_knots(proj)\n",
        "\n",
        "                for k in knots:\n",
        "                    for sign in [1, -1]:\n",
        "                        h = np.maximum(sign * (proj - k), 0.0)\n",
        "\n",
        "                        if self._check_linear_independence(h, terms[1:]):\n",
        "                            temp_terms = terms + [h]\n",
        "                            design = np.column_stack(temp_terms)\n",
        "\n",
        "                            try:\n",
        "                                coef = np.linalg.lstsq(design, y, rcond=None)[0]\n",
        "                                pred = design @ coef\n",
        "                                gcv = self._gcv(y, pred, len(temp_terms), True)\n",
        "\n",
        "                                if gcv < best_gcv:\n",
        "                                    best_gcv = gcv\n",
        "                                    best_config = (a, k, sign, h, coef)\n",
        "                            except np.linalg.LinAlgError:\n",
        "                                continue\n",
        "\n",
        "            if best_config is None or best_gcv >= self.gcv_scores[-1]:\n",
        "                break\n",
        "\n",
        "            a, k, sign, h, coef = best_config\n",
        "            self.directions.append(a)\n",
        "            self.knots.append(k)\n",
        "            self.signs.append(sign)\n",
        "            terms.append(h)\n",
        "\n",
        "            self.a0 = float(coef[0])\n",
        "            self.alphas = list(coef[1:])\n",
        "\n",
        "            preds.append(terms[-1])\n",
        "            self.gcv_scores.append(best_gcv)\n",
        "\n",
        "            y_pred = self.predict(X)\n",
        "            r2 = 1 - np.sum((y - y_pred)**2) / np.sum((y - np.mean(y))**2)\n",
        "            self.r2_scores.append(r2)\n",
        "\n",
        "        return self\n",
        "\n",
        "    def predict(self, X: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"Przewiduje wartości dla nowych danych\"\"\"\n",
        "        X = np.asarray(X)\n",
        "        n = X.shape[0]\n",
        "        pred = np.full(n, self.a0)\n",
        "\n",
        "        for i, (direction, knot, sign, alpha) in enumerate(zip(\n",
        "            self.directions, self.knots, self.signs, self.alphas)):\n",
        "            proj = X @ direction\n",
        "            term = np.maximum(sign * (proj - knot), 0.0)\n",
        "            pred += alpha * term\n",
        "\n",
        "        return pred\n",
        "\n",
        "    def conditional_expectation(self, X_prev: np.ndarray, r: float,\n",
        "                              sigma_vec: np.ndarray, rho_corr: np.ndarray,\n",
        "                              dt: float, n_mc: int = 100) -> np.ndarray:\n",
        "        \"\"\"Oblicza warunkową wartość oczekiwaną\"\"\"\n",
        "        n_paths = X_prev.shape[0]\n",
        "        result = np.zeros(n_paths)\n",
        "\n",
        "        drift = (r - 0.5 * sigma_vec**2) * dt\n",
        "        diffusion = sigma_vec * np.sqrt(dt)\n",
        "\n",
        "        for _ in range(n_mc):\n",
        "            Z = np.random.standard_normal((n_paths, len(sigma_vec)))\n",
        "            if len(sigma_vec) > 1:\n",
        "                Z = Z @ np.linalg.cholesky(rho_corr).T\n",
        "\n",
        "            X_next = X_prev * np.exp(drift + diffusion * Z)\n",
        "            pred = self.predict(X_next)\n",
        "            pred = np.clip(pred, -1e6, 1e6)  # Zabezpieczenie przed ekstremalnymi wartościami\n",
        "            result += pred\n",
        "\n",
        "        return result / n_mc\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# Główna funkcja wyceny\n",
        "# ---------------------------\n",
        "\n",
        "def price_american_option(\n",
        "    payoff_fn: Callable[[np.ndarray], float],\n",
        "    d: int,\n",
        "    n_steps: int,\n",
        "    r: float,\n",
        "    sigma: float,\n",
        "    S0: float,\n",
        "    K: float,\n",
        "    N1: int = 2048,\n",
        "    N2: int = 4096,\n",
        "    qmc_method: str = 'sobol_scrambled',\n",
        "    seed: Optional[int] = None,\n",
        "    max_mars_terms: int = 15,\n",
        "    rho_corr: Optional[np.ndarray] = None,\n",
        "    T: float = 1.0  # Czas do wygaśnięcia w latach\n",
        ") -> Tuple[float, float, float]:\n",
        "    \"\"\"\n",
        "    Zwraca (lower_bound, upper_bound, point_estimate)\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    n_steps : int\n",
        "        Liczba kroków czasowych\n",
        "    T : float\n",
        "        Czas do wygaśnięcia w latach (domyślnie 1.0)\n",
        "    \"\"\"\n",
        "    dt = T / n_steps\n",
        "\n",
        "    if rho_corr is None:\n",
        "        rho_corr = np.eye(d)\n",
        "    else:\n",
        "        assert rho_corr.shape == (d, d)\n",
        "\n",
        "    S0_vec = np.full(d, S0)\n",
        "    sigma_vec = np.full(d, sigma)\n",
        "\n",
        "    # Inicjalizacja QMC samplera z właściwym wymiarem\n",
        "    total_dim = n_steps * d\n",
        "    if qmc_method == 'halton':\n",
        "        qmc1 = Halton(dimension=total_dim, seed=seed)\n",
        "    elif qmc_method == 'sobol':\n",
        "        qmc1 = Sobol(dimension=total_dim, seed=seed)\n",
        "    elif qmc_method == 'sobol_scrambled':\n",
        "        qmc1 = Sobol(dimension=total_dim, randomize='Owen', seed=seed)\n",
        "    else:\n",
        "        raise ValueError(\"Nieznana metoda QMC\")\n",
        "\n",
        "    # Faza I: Dopasowanie strategii i MARS\n",
        "    paths1 = simulate_paths(S0_vec, r, sigma_vec, rho_corr, n_steps, T, N1, qmc1, seed)\n",
        "    Y = np.array([payoff_fn(paths1[n, -1, :]) for n in range(N1)])\n",
        "    cv = np.zeros(N1)\n",
        "\n",
        "    # Inicjalizacja modeli\n",
        "    mars_models = [None] * (n_steps + 1)\n",
        "    mars_models[-1] = ExtendedMARS(max_terms=1)\n",
        "    mars_models[-1].a0 = float(np.mean(Y))\n",
        "    mars_models[-1].alphas = []\n",
        "    mars_models[-1].directions = []\n",
        "    mars_models[-1].knots = []\n",
        "\n",
        "    # Regresje LSM\n",
        "    alpha_ls = [None] * n_steps\n",
        "\n",
        "    # Backward induction\n",
        "    for t in range(n_steps - 1, -1, -1):\n",
        "        X_next = paths1[:, t + 1, :]\n",
        "        mars = ExtendedMARS(max_terms=max_mars_terms)\n",
        "        mars.fit(X_next, Y)\n",
        "        mars_models[t + 1] = mars\n",
        "\n",
        "        # Oblicz martyngał kontrolny\n",
        "        X_curr = paths1[:, t, :]\n",
        "        exp_mars = mars.conditional_expectation(X_curr, r, sigma_vec, rho_corr, dt)\n",
        "        cv += mars.predict(X_next) - exp_mars\n",
        "\n",
        "        # Znajdź opcje ITM\n",
        "        exercise_value = np.array([payoff_fn(paths1[n, t, :]) for n in range(N1)])\n",
        "        itm = exercise_value > 0\n",
        "\n",
        "        if not np.any(itm):\n",
        "            alpha_ls[t] = np.zeros(1 + 2 * d)\n",
        "            Y *= np.exp(-r * dt)\n",
        "            cv *= np.exp(-r * dt)\n",
        "            continue\n",
        "\n",
        "        # Oblicz wartość kontynuacji dla ITM\n",
        "        X_itm = paths1[itm, t, :]\n",
        "        phi = np.hstack([np.ones((X_itm.shape[0], 1)), X_itm, X_itm ** 2])\n",
        "        Y_reg = Y[itm] - cv[itm]  # Użyj martyngału jako zmiennej kontrolnej\n",
        "\n",
        "        try:\n",
        "            alpha_t, *_ = np.linalg.lstsq(phi, Y_reg, rcond=None)\n",
        "            alpha_t = alpha_t.ravel()\n",
        "        except np.linalg.LinAlgError:\n",
        "            alpha_t = np.zeros(phi.shape[1])\n",
        "\n",
        "        alpha_ls[t] = alpha_t\n",
        "\n",
        "        # Aktualizacja wartości\n",
        "        for n in range(N1):\n",
        "            if itm[n]:\n",
        "                cont = float(alpha_t @ np.hstack([1.0, paths1[n, t, :], paths1[n, t, :] ** 2]))\n",
        "                if exercise_value[n] > cont:\n",
        "                    Y[n] = exercise_value[n]\n",
        "                    cv[n] = 0.0\n",
        "                else:\n",
        "                    Y[n] *= np.exp(-r * dt)\n",
        "                    cv[n] *= np.exp(-r * dt)\n",
        "            else:\n",
        "                Y[n] *= np.exp(-r * dt)\n",
        "                cv[n] *= np.exp(-r * dt)\n",
        "\n",
        "    # Faza II: Estymacja granic\n",
        "    # Inicjalizacja QMC samplera\n",
        "    if qmc_method == 'halton':\n",
        "        qmc2 = Halton(dimension=total_dim, seed=(seed + 1) if seed is not None else None)\n",
        "    elif qmc_method == 'sobol':\n",
        "        qmc2 = Sobol(dimension=total_dim, seed=(seed + 1) if seed is not None else None)\n",
        "    elif qmc_method == 'sobol_scrambled':\n",
        "        qmc2 = Sobol(dimension=total_dim, randomize='Owen', seed=(seed + 1) if seed is not None else None)\n",
        "    else:\n",
        "        raise ValueError(\"Nieznana metoda QMC\")\n",
        "    paths2 = simulate_paths(S0_vec, r, sigma_vec, rho_corr, n_steps, T, N2, qmc2, seed)\n",
        "\n",
        "    # Oblicz martyngał kontrolny dla drugiej fazy\n",
        "    pi = np.zeros((N2, n_steps + 1))\n",
        "    for t in range(1, n_steps + 1):\n",
        "        X_t = paths2[:, t, :]\n",
        "        X_prev = paths2[:, t - 1, :]\n",
        "\n",
        "        h_t = mars_models[t].predict(X_t)\n",
        "        exp_h = mars_models[t].conditional_expectation(X_prev, r, sigma_vec, rho_corr, dt)\n",
        "\n",
        "        # Bardziej stabilne obliczanie przyrostu martyngału\n",
        "        increment = np.exp(-r * (t-1) * dt) * (h_t - exp_h)\n",
        "        increment = np.clip(increment, -1e6, 1e6)  # Zabezpieczenie przed ekstremalnymi wartościami\n",
        "        pi[:, t] = pi[:, t-1] + increment\n",
        "\n",
        "    # Znajdź optymalne czasy wykonania\n",
        "    tau = np.full(N2, n_steps)\n",
        "    for n in range(N2):\n",
        "        for t in range(n_steps):\n",
        "            exercise_value = payoff_fn(paths2[n, t, :])\n",
        "            if exercise_value > 0:\n",
        "                alpha_t = alpha_ls[t]\n",
        "                if alpha_t is not None:\n",
        "                    cont = float(alpha_t @ np.hstack([1.0, paths2[n, t, :], paths2[n, t, :] ** 2]))\n",
        "                    if exercise_value > cont:\n",
        "                        tau[n] = t\n",
        "                        break\n",
        "\n",
        "    # Oblicz dolne ograniczenie z martyngałem kontrolnym\n",
        "    disc_payoff = np.exp(-r * tau * dt) * np.array([\n",
        "        payoff_fn(paths2[n, tau[n], :]) for n in range(N2)\n",
        "    ])\n",
        "    lower = np.mean(disc_payoff - pi[np.arange(N2), tau])\n",
        "\n",
        "    # Oblicz górne ograniczenie używając martyngału\n",
        "    upper_vals = []\n",
        "    for n in range(N2):\n",
        "        vals = [\n",
        "            np.exp(-r * t * dt) * payoff_fn(paths2[n, t, :]) - pi[n, t]\n",
        "            for t in range(n_steps + 1)\n",
        "        ]\n",
        "        upper_vals.append(max(vals))\n",
        "    upper = np.mean(upper_vals)\n",
        "\n",
        "    point = 0.5 * (lower + upper)\n",
        "\n",
        "    return lower, upper, point\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# Przykład użycia (test)\n",
        "# ---------------------------\n",
        "import os\n",
        "if __name__ == \"__main__\":\n",
        "    # Parametry testowe\n",
        "    d = 1\n",
        "    r = 0.05        # 5% stopa procentowa\n",
        "    sigma = 0.2     # 20% zmienność\n",
        "    S0 = 100.0      # Cena początkowa\n",
        "    K = 100.0       # Cena wykonania\n",
        "    T = 1.0         # Czas do wygaśnięcia (1 rok)\n",
        "    rho = np.eye(d)\n",
        "\n",
        "    # Funkcja wypłaty dla opcji put\n",
        "    payoff = lambda x: max(K - x[0], 0.0)\n",
        "\n",
        "    # Przygotuj nazwę pliku z aktualną datą i czasem\n",
        "    from datetime import datetime\n",
        "    timestamp = datetime.utcnow().strftime('%Y%m%d_%H%M%S')\n",
        "    filename = f\"american_option_results_{timestamp}.txt\"\n",
        "\n",
        "    # Zapisz parametry do pliku\n",
        "    with open(filename, 'w') as f:\n",
        "        f.write(f\"Data i czas (UTC): {datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
        "        f.write(f\"Użytkownik: {os.getenv('USERNAME')}\\n\")\n",
        "        f.write(\"\\nParametry symulacji:\\n\")\n",
        "        f.write(f\"S0 = {S0}\\n\")\n",
        "        f.write(f\"K = {K}\\n\")\n",
        "        f.write(f\"r = {r}\\n\")\n",
        "        f.write(f\"sigma = {sigma}\\n\")\n",
        "        f.write(f\"T = {T}\\n\")\n",
        "        f.write(\"Typ opcji: PUT\\n\")\n",
        "        f.write(\"\\nWyniki:\\n\")\n",
        "        f.write(\"-\" * 50 + \"\\n\")\n",
        "\n",
        "    # Test dla różnych liczb kroków czasowych\n",
        "    n_steps_list = [1, 2, 4, 8, 16, 32, 64, 128, 256, 512, 1000, 1500, 2000, 3000, 5000]\n",
        "\n",
        "    for n_steps in n_steps_list:\n",
        "        print(f\"\\nLiczba kroków czasowych: {n_steps}\")\n",
        "\n",
        "        # Adaptacyjna liczba symulacji (zawsze potęga 2)\n",
        "        N1_base = 8192\n",
        "        N2_base = 4096\n",
        "        # N1 = next_power_of_2(N1_base * (1 + n_steps // 32))\n",
        "        # N2 = next_power_of_2(N2_base * (1 + n_steps // 32))\n",
        "\n",
        "        # Wycena opcji\n",
        "        lb, ub, pe = price_american_option(\n",
        "            payoff_fn=payoff,\n",
        "            d=d,\n",
        "            n_steps=n_steps,\n",
        "            T=T,\n",
        "            r=r,\n",
        "            sigma=sigma,\n",
        "            S0=S0,\n",
        "            K=K,\n",
        "            N1=N1_base,\n",
        "            N2=N2_base,\n",
        "            qmc_method='sobol_scrambled',\n",
        "            seed=42,\n",
        "            max_mars_terms=20,\n",
        "            rho_corr=rho\n",
        "        )\n",
        "\n",
        "        # Wyświetl wyniki\n",
        "        print(f\"Dolne ograniczenie: {lb:.4f}\")\n",
        "        print(f\"Górne ograniczenie: {ub:.4f}\")\n",
        "        print(f\"Szacowana cena:     {pe:.4f}\")\n",
        "        print(f\"Szerokość przedziału: {ub-lb:.4f}\")\n",
        "\n",
        "        # Zapisz wyniki do pliku\n",
        "        with open(filename, 'a') as f:\n",
        "            f.write(f\"\\nLiczba kroków czasowych: {n_steps}\\n\")\n",
        "            f.write(f\"Liczba symulacji N1: {N1_base}\\n\")\n",
        "            f.write(f\"Liczba symulacji N2: {N2_base}\\n\")\n",
        "            f.write(f\"Dolne ograniczenie: {lb:.4f}\\n\")\n",
        "            f.write(f\"Górne ograniczenie: {ub:.4f}\\n\")\n",
        "            f.write(f\"Szacowana cena:     {pe:.4f}\\n\")\n",
        "            f.write(f\"Szerokość przedziału: {ub-lb:.4f}\\n\")\n",
        "            f.write(\"-\" * 30 + \"\\n\")\n",
        "\n",
        "    # Dodaj podsumowanie na końcu pliku\n",
        "    with open(filename, 'a') as f:\n",
        "        f.write(\"\\nKoniec symulacji\\n\")\n",
        "        f.write(f\"Całkowity czas wykonania: {datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S')}\\n\")"
      ]
    }
  ]
}